{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in ./.venv/lib/python3.13/site-packages (4.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in ./.venv/lib/python3.13/site-packages (from pyspark) (0.10.9.9)\n",
            "Requirement already satisfied: findspark in ./.venv/lib/python3.13/site-packages (2.0.1)\n",
            "Requirement already satisfied: wordcloud in ./.venv/lib/python3.13/site-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in ./.venv/lib/python3.13/site-packages (from wordcloud) (2.3.0)\n",
            "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from wordcloud) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.13/site-packages (from seaborn) (2.3.0)\n",
            "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.13/site-packages (from seaborn) (2.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.13/site-packages (from seaborn) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
            "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
            "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
            "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
            "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m More information is available at\n",
            "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3  install pyspark\n",
        "!pip3 install findspark\n",
        "!pip3 install wordcloud\n",
        "!pip3 install matplotlib\n",
        "!pip3 install seaborn\n",
        "!pip3 install sklearn\n",
        "!pip3 install pandas\n",
        "!pip3 install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hAVjuyepzP7s"
      },
      "outputs": [],
      "source": [
        "# ====================================\n",
        "# ðŸ”§ SETUP & IMPORTS\n",
        "# ====================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, concat_ws, udf\n",
        "from pyspark.sql.types import BooleanType\n",
        "from pyspark.ml.feature import (\n",
        "    Tokenizer, StopWordsRemover, CountVectorizer, HashingTF, IDF, MinHashLSH\n",
        ")\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XDuFqoOuzqux",
        "outputId": "5e08e52d-09ef-49ee-8219-6f2f636f56fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: kaggle.json: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Create the .kaggle directory and move the file\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in ./.venv/lib/python3.13/site-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (2025.4.26)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/moeinghaeini/Desktop/Amazon Book Review/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "!pip3 install kagglehub\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byf1oMRHztMU",
        "outputId": "0bb3f14d-67d9-4bbb-a098-307eb27291a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yc/m8cs0qcn1lg94kgtm6j1s0th0000gn/T/ipykernel_29606/3121204917.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading books_data.csv ...\n",
            "Saved books_data.csv to dataset/full_dataset/books_data.csv\n",
            "Loading Books_rating.csv ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yc/m8cs0qcn1lg94kgtm6j1s0th0000gn/T/ipykernel_29606/3121204917.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Books_rating.csv to dataset/full_dataset/Books_rating.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# List of CSV files in the dataset\n",
        "file_names = [\n",
        "    \"books_data.csv\", \"Books_rating.csv\"\n",
        "]\n",
        "\n",
        "# Directory to save CSVs locally\n",
        "save_dir = \"dataset/full_dataset\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Loop through all files, load and save locally\n",
        "for file_name in file_names:\n",
        "    print(f\"Loading {file_name} ...\")\n",
        "    df = kagglehub.load_dataset(\n",
        "        KaggleDatasetAdapter.PANDAS,\n",
        "        \"mohamedbakhet/amazon-books-reviews\",\n",
        "        file_name,\n",
        "    )\n",
        "    save_path = os.path.join(save_dir, file_name)\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Saved {file_name} to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zvy7qIN7zWkt"
      },
      "outputs": [],
      "source": [
        "# --- SparkContext setup\n",
        "# ====================================\n",
        "# ðŸš€ INITIATE SPARK\n",
        "# ====================================\n",
        "spark = SparkSession.builder.appName(\"SimilarBooksAcademic\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RhPZBJyfHFtR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "books = spark.read.csv(\"dataset/full_dataset/books_data.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"dataset/full_dataset/Books_rating.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mCno6b-IAzn",
        "outputId": "4c235e1a-970b-47c8-f0f9-9b9d403f01bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Title: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- authors: string (nullable = true)\n",
            " |-- image: string (nullable = true)\n",
            " |-- previewLink: string (nullable = true)\n",
            " |-- publisher: string (nullable = true)\n",
            " |-- publishedDate: string (nullable = true)\n",
            " |-- infoLink: string (nullable = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- ratingsCount: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Price: string (nullable = true)\n",
            " |-- User_id: string (nullable = true)\n",
            " |-- profileName: string (nullable = true)\n",
            " |-- review/helpfulness: string (nullable = true)\n",
            " |-- review/score: string (nullable = true)\n",
            " |-- review/time: string (nullable = true)\n",
            " |-- review/summary: string (nullable = true)\n",
            " |-- review/text: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# prompt: print schema\n",
        "\n",
        "books.printSchema()\n",
        "ratings.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in ./.venv/lib/python3.13/site-packages (3.9.1)\n",
            "Requirement already satisfied: click in ./.venv/lib/python3.13/site-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in ./.venv/lib/python3.13/site-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, MinHashLSH\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/moeinghaeini/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/moeinghaeini/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/moeinghaeini/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in ./.venv/lib/python3.13/site-packages (4.0.0)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in ./.venv/lib/python3.13/site-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading full dataset...\n",
            "Sampling 10% of the data...\n",
            "Saving sampled data...\n",
            "Original dataset size: 3000000 reviews\n",
            "Sampled dataset size: 300000 reviews\n",
            "Sampled data saved to: sampled_data/Books_rating_sampled.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Create a new directory for sampled data\n",
        "if not os.path.exists('sampled_data'):\n",
        "    os.makedirs('sampled_data')\n",
        "\n",
        "# Load the full dataset\n",
        "print(\"Loading full dataset...\")\n",
        "df = pd.read_csv('dataset/full_dataset/Books_rating.csv')\n",
        "\n",
        "# Sample 10% of the data with random_state for reproducibility\n",
        "print(\"Sampling 10% of the data...\")\n",
        "sampled_df = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Save the sampled data\n",
        "print(\"Saving sampled data...\")\n",
        "sampled_df.to_csv('sampled_data/Books_rating_sampled.csv', index=False)\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Original dataset size: {len(df)} reviews\")\n",
        "print(f\"Sampled dataset size: {len(sampled_df)} reviews\")\n",
        "print(f\"Sampled data saved to: sampled_data/Books_rating_sampled.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading full dataset...\n",
            "Sampling 10% of the data...\n",
            "Saving sampled data...\n",
            "Original dataset size: 212404 reviews\n",
            "Sampled dataset size: 21240 reviews\n",
            "Sampled data saved to: sampled_data/books_data_sampled.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Create a new directory for sampled data\n",
        "if not os.path.exists('sampled_data'):\n",
        "    os.makedirs('sampled_data')\n",
        "\n",
        "# Load the full dataset\n",
        "print(\"Loading full dataset...\")\n",
        "df = pd.read_csv('dataset/full_dataset/books_data.csv')\n",
        "\n",
        "# Sample 10% of the data with random_state for reproducibility\n",
        "print(\"Sampling 10% of the data...\")\n",
        "sampled_df = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Save the sampled data\n",
        "print(\"Saving sampled data...\")\n",
        "sampled_df.to_csv('sampled_data/books_data_sampled.csv', index=False)\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Original dataset size: {len(df)} reviews\")\n",
        "print(f\"Sampled dataset size: {len(sampled_df)} reviews\")\n",
        "print(f\"Sampled data saved to: sampled_data/books_data_sampled.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
